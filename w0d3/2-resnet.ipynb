{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch as t\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from einops import reduce, rearrange\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm2d(nn.Module):\n",
    "    running_mean: t.Tensor         # shape: (num_features,)\n",
    "    running_var: t.Tensor          # shape: (num_features,)\n",
    "    num_batches_tracked: t.Tensor  # shape: ()\n",
    "\n",
    "    def __init__(self, num_features: int, eps=1e-05, momentum=0.1):\n",
    "        '''Like nn.BatchNorm2d with track_running_stats=True and affine=True.\n",
    "\n",
    "        Name the learnable affine parameters `weight` and `bias` in that order.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.weight = nn.Parameter(t.ones(num_features))\n",
    "        self.bias = nn.Parameter(t.zeros(num_features))\n",
    "        \n",
    "        self.register_buffer(\"running_mean\", t.zeros(num_features))\n",
    "        self.register_buffer(\"running_var\", t.ones(num_features))\n",
    "        self.register_buffer(\"num_batches_tracked\", t.tensor(0))\n",
    "        \n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        '''Normalize each channel.\n",
    "\n",
    "        Compute the variance using `torch.var(x, unbiased=False)`\n",
    "        Hint: you may also find it helpful to use the argument `keepdim`.\n",
    "\n",
    "        x: shape (batch, channels, height, width)\n",
    "        Return: shape (batch, channels, height, width)\n",
    "        '''\n",
    "        if self.training:\n",
    "            self.num_batches_tracked += 1\n",
    "\n",
    "            mean = t.mean(x, dim=(0, 2, 3), keepdim=True)\n",
    "            var = t.var(x, dim=(0, 2, 3), unbiased=False, keepdim=True)\n",
    "\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + \\\n",
    "                                self.momentum * mean.squeeze()\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + \\\n",
    "                                self.momentum * var.squeeze()\n",
    "        else:\n",
    "            mean = rearrange(self.running_mean, \"c -> 1 c 1 1\")\n",
    "            var = rearrange(self.running_var, \"c -> 1 c 1 1\")\n",
    "\n",
    "        weight = rearrange(self.weight, \"c -> 1 c 1 1\")\n",
    "        bias = rearrange(self.bias, \"c -> 1 c 1 1\")\n",
    "        return ((x - mean) / t.sqrt(var + self.eps)) * weight + bias\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \", \".join(\n",
    "            [f\"{key}={getattr(self, key)}\" for key in [\"num_features\", \"eps\", \"momentum\"]]\n",
    "        )\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     utils.test_batchnorm2d_module(BatchNorm2d)\n",
    "#     utils.test_batchnorm2d_forward(BatchNorm2d)\n",
    "#     utils.test_batchnorm2d_running_mean(BatchNorm2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool(nn.Module):\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        '''\n",
    "        x: shape (batch, channels, height, width)\n",
    "        Return: shape (batch, channels)\n",
    "        '''\n",
    "        return reduce(x, 'b c h w -> b c 1 1', 'mean')\n",
    "\n",
    "# Testing\n",
    "if __name__ == \"__main__\":\n",
    "    for c in range(1, 10):\n",
    "        x = t.rand(4, c, c+2, c+2)\n",
    "        t.testing.assert_close(AveragePool()(x), nn.AdaptiveAvgPool2d((1, 1))(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
    "        '''A single residual block with optional downsampling.\n",
    "\n",
    "        For compatibility with the pretrained model, declare the left side branch first\n",
    "        a `Sequential`.\n",
    "\n",
    "        If first_stride is > 1, this means the optional (conv + bn) should be present on the\n",
    "        right branch. Declare it second using another `Sequential`.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        if first_stride == 1:\n",
    "            assert in_feats == out_feats, \\\n",
    "                \"Invalid ResBlock: if first_stride==1, we require in_feats == out_feats\"\n",
    "\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_feats, out_feats,\n",
    "                kernel_size=3, stride=first_stride, padding=1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_feats, out_feats, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_feats)\n",
    "        )\n",
    "\n",
    "        if first_stride <= 1:\n",
    "            self.right = nn.Identity()\n",
    "        else:\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(in_feats, out_feats, kernel_size=1, stride=first_stride, bias=False),\n",
    "                nn.BatchNorm2d(out_feats)\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        '''Compute the forward pass.\n",
    "\n",
    "        x: shape (batch, in_feats, height, width)\n",
    "\n",
    "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
    "\n",
    "        If no downsampling block is present, the addition should just add the left branch's output\n",
    "        to the input.\n",
    "        '''\n",
    "        return self.relu(self.left(x) + self.right(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockGroup(nn.Module):\n",
    "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
    "        '''An n_blocks-long sequence of ResidualBlock where only the first block uses\n",
    "        the provided stride.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            ResidualBlock(in_feats, out_feats, first_stride),\n",
    "            *[ResidualBlock(out_feats, out_feats, 1) for _ in range(n_blocks-1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        '''Compute the forward pass.\n",
    "        x: shape (batch, in_feats, height, width)\n",
    "\n",
    "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
    "        '''\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_blocks_per_group=[3, 4, 6, 3],\n",
    "        out_features_per_group=[64, 128, 256, 512],\n",
    "        first_strides_per_group=[1, 2, 2, 2],\n",
    "        n_classes=1000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert (\n",
    "            len(n_blocks_per_group) == len(out_features_per_group) == len(first_strides_per_group)\n",
    "        ), \"BlockGroup params need to properly defined.\"\n",
    "\n",
    "        in_feat = 64\n",
    "        in_features_per_group = [in_feat] + out_features_per_group[:-1]\n",
    "        zipped_params = zip(\n",
    "            n_blocks_per_group,\n",
    "            in_features_per_group,\n",
    "            out_features_per_group,\n",
    "            first_strides_per_group\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, in_feat, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(in_feat),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            *[BlockGroup(*params) for params in zipped_params],\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(out_features_per_group[-1], n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        '''\n",
    "        x: shape (batch, channels, height, width)\n",
    "\n",
    "        Return: shape (batch, n_classes)\n",
    "        '''\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resnet = ResNet34().eval()\n",
    "pt_resnet = torchvision.models.resnet34(weights=\"DEFAULT\").eval()\n",
    "# Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to\n",
    "# /home/jmsdao/.cache/torch/hub/checkpoints/resnet34-b627a593.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_weights(\n",
    "        myresnet: ResNet34,\n",
    "        pretrained_resnet: torchvision.models.resnet.ResNet\n",
    "    ) -> ResNet34:\n",
    "    '''Copy over the weights of `pretrained_resnet` to your resnet.'''\n",
    "\n",
    "    mydict = myresnet.state_dict().items()\n",
    "    pretraineddict = pretrained_resnet.state_dict().items()\n",
    "\n",
    "    # Check the number of params/buffers is correct\n",
    "    assert len(mydict) == len(pretraineddict), \\\n",
    "        \"Number of layers is wrong. Have you done the prev step correctly?\"\n",
    "\n",
    "    # Initialise an empty dictionary to store the correct key-value pairs\n",
    "    state_dict_to_load = {}\n",
    "\n",
    "    for (mykey, myvalue), (pretrainedkey, pretrainedvalue) in zip(mydict, pretraineddict):\n",
    "        state_dict_to_load[mykey] = pretrainedvalue\n",
    "\n",
    "    myresnet.load_state_dict(state_dict_to_load)\n",
    "\n",
    "    return myresnet\n",
    "\n",
    "my_resnet = copy_weights(my_resnet, pt_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILENAMES = [\n",
    "    \"chimpanzee.jpg\",\n",
    "    \"golden_retriever.jpg\",\n",
    "    \"platypus.jpg\",\n",
    "    \"frogs.jpg\",\n",
    "    \"fireworks.jpg\",\n",
    "    \"astronaut.jpg\",\n",
    "    \"iguana.jpg\",\n",
    "    \"volcano.jpg\",\n",
    "    \"goofy.jpg\",\n",
    "    \"dragonfly.jpg\",\n",
    "]\n",
    "\n",
    "IMAGE_FOLDER = Path(\"./resnet_inputs\")\n",
    "\n",
    "images = [Image.open(IMAGE_FOLDER / filename) for filename in IMAGE_FILENAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(images: List[Image.Image]) -> t.Tensor:\n",
    "    '''\n",
    "    Return: shape (batch=len(images), num_channels=3, height=224, width=224)\n",
    "    '''\n",
    "    tf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    return t.stack(tuple(map(tf, images)), dim=0)\n",
    "\n",
    "prepared_images = prepare_data(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, images):\n",
    "#     logits = model(images)\n",
    "#     return logits.argmax(dim=1)\n",
    "\n",
    "# my_preds = predict(my_resnet, prepared_images)\n",
    "# pt_preds = predict(pt_resnet, prepared_images)\n",
    "\n",
    "my_logits = my_resnet(prepared_images)\n",
    "pt_logits = pt_resnet(prepared_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imagenet_labels.json\") as f:\n",
    "    imagenet_labels = list(json.load(f).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.testing.assert_close(my_logits, pt_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image filename: chimpanzee.jpg\n",
      "  my_resnet top 3:\n",
      "    (19.29) chimpanzee, chimp, Pan troglodytes\n",
      "    (15.70) siamang, Hylobates syndactylus, Symphalangus syndactylus\n",
      "    (12.54) gorilla, Gorilla gorilla\n",
      "  pt_resnet top 3:\n",
      "    (19.29) chimpanzee, chimp, Pan troglodytes\n",
      "    (15.70) siamang, Hylobates syndactylus, Symphalangus syndactylus\n",
      "    (12.54) gorilla, Gorilla gorilla\n",
      "\n",
      "Image filename: golden_retriever.jpg\n",
      "  my_resnet top 3:\n",
      "    (12.12) golden retriever\n",
      "    (8.31) Newfoundland, Newfoundland dog\n",
      "    (8.30) Pekinese, Pekingese, Peke\n",
      "  pt_resnet top 3:\n",
      "    (12.12) golden retriever\n",
      "    (8.31) Newfoundland, Newfoundland dog\n",
      "    (8.30) Pekinese, Pekingese, Peke\n",
      "\n",
      "Image filename: platypus.jpg\n",
      "  my_resnet top 3:\n",
      "    (18.12) platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\n",
      "    (11.81) electric ray, crampfish, numbfish, torpedo\n",
      "    (11.17) stingray\n",
      "  pt_resnet top 3:\n",
      "    (18.12) platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\n",
      "    (11.81) electric ray, crampfish, numbfish, torpedo\n",
      "    (11.17) stingray\n",
      "\n",
      "Image filename: frogs.jpg\n",
      "  my_resnet top 3:\n",
      "    (10.06) toyshop\n",
      "    (9.61) pinwheel\n",
      "    (8.93) comic book\n",
      "  pt_resnet top 3:\n",
      "    (10.06) toyshop\n",
      "    (9.61) pinwheel\n",
      "    (8.93) comic book\n",
      "\n",
      "Image filename: fireworks.jpg\n",
      "  my_resnet top 3:\n",
      "    (12.67) fountain\n",
      "    (11.14) pineapple, ananas\n",
      "    (8.35) bearskin, busby, shako\n",
      "  pt_resnet top 3:\n",
      "    (12.67) fountain\n",
      "    (11.14) pineapple, ananas\n",
      "    (8.35) bearskin, busby, shako\n",
      "\n",
      "Image filename: astronaut.jpg\n",
      "  my_resnet top 3:\n",
      "    (9.85) liner, ocean liner\n",
      "    (9.28) paddlewheel, paddle wheel\n",
      "    (8.22) dome\n",
      "  pt_resnet top 3:\n",
      "    (9.85) liner, ocean liner\n",
      "    (9.28) paddlewheel, paddle wheel\n",
      "    (8.22) dome\n",
      "\n",
      "Image filename: iguana.jpg\n",
      "  my_resnet top 3:\n",
      "    (18.81) common iguana, iguana, Iguana iguana\n",
      "    (11.23) agama\n",
      "    (11.14) frilled lizard, Chlamydosaurus kingi\n",
      "  pt_resnet top 3:\n",
      "    (18.81) common iguana, iguana, Iguana iguana\n",
      "    (11.23) agama\n",
      "    (11.14) frilled lizard, Chlamydosaurus kingi\n",
      "\n",
      "Image filename: volcano.jpg\n",
      "  my_resnet top 3:\n",
      "    (23.41) volcano\n",
      "    (10.01) frying pan, frypan, skillet\n",
      "    (9.93) mountain tent\n",
      "  pt_resnet top 3:\n",
      "    (23.41) volcano\n",
      "    (10.01) frying pan, frypan, skillet\n",
      "    (9.93) mountain tent\n",
      "\n",
      "Image filename: goofy.jpg\n",
      "  my_resnet top 3:\n",
      "    (9.24) binoculars, field glasses, opera glasses\n",
      "    (8.20) picket fence, paling\n",
      "    (7.88) plunger, plumber's helper\n",
      "  pt_resnet top 3:\n",
      "    (9.24) binoculars, field glasses, opera glasses\n",
      "    (8.20) picket fence, paling\n",
      "    (7.88) plunger, plumber's helper\n",
      "\n",
      "Image filename: dragonfly.jpg\n",
      "  my_resnet top 3:\n",
      "    (7.35) banana\n",
      "    (7.08) coil, spiral, volute, whorl, helix\n",
      "    (6.97) bucket, pail\n",
      "  pt_resnet top 3:\n",
      "    (7.35) banana\n",
      "    (7.08) coil, spiral, volute, whorl, helix\n",
      "    (6.97) bucket, pail\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "for i, filename in enumerate(IMAGE_FILENAMES):\n",
    "    print('\\nImage filename:', filename)\n",
    "\n",
    "    print(f'  my_resnet top {k}:')\n",
    "    for value, index in zip(*my_logits[i].topk(k)):\n",
    "        print(f'    ({value:.2f}) {imagenet_labels[index]}')\n",
    "\n",
    "    print(f'  pt_resnet top {k}:')\n",
    "    for value, index in zip(*pt_logits[i].topk(k)):\n",
    "        print(f'    ({value:.2f}) {imagenet_labels[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('arena')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84205e65a427e19ff91dd8a92d5a5f2cf0946f21e31957c24c166022f0f50b37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
