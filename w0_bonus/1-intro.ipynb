{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any, Callable, Iterable, Iterator, Optional, Union, Tuple\n",
    "import utils\n",
    "\n",
    "Arr = np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests in `test_einsum_inner` passed!\n"
     ]
    }
   ],
   "source": [
    "def log_back(grad_out: Arr, out: Arr, x: Arr) -> Arr:\n",
    "    '''Backwards function for f(x) = log(x)\n",
    "\n",
    "    grad_out: gradient of some loss wrt out\n",
    "    out: the output of np.log(x)\n",
    "    x: the input of np.log\n",
    "\n",
    "    Return: gradient of the given loss wrt x\n",
    "    '''\n",
    "    return grad_out * (1 / x)\n",
    "\n",
    "utils.test_log_back(log_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests in `test_unbroadcast` passed!\n"
     ]
    }
   ],
   "source": [
    "def unbroadcast(broadcasted: Arr, original: Arr) -> Arr:\n",
    "    '''Sum 'broadcasted' until it has the shape of 'original'.\n",
    "\n",
    "    broadcasted: An array that was formerly of the same shape of 'original'\n",
    "    and was expanded by broadcasting rules.\n",
    "    '''\n",
    "    # Sum and remove dimensions that were prepended to the front of the original shape.\n",
    "    n_dims_prepended = len(broadcasted.shape) - len(original.shape)\n",
    "    unbroadcasted = broadcasted.sum(axis=tuple(range(n_dims_prepended)))\n",
    "\n",
    "    # Sum dimensions that were originally 1 back to the size 1 (using keepdims=True).\n",
    "    for dim, os in enumerate(original.shape):\n",
    "        if os == 1:\n",
    "            unbroadcasted = unbroadcasted.sum(axis=dim, keepdims=True)\n",
    "    \n",
    "    return unbroadcasted\n",
    "\n",
    "utils.test_unbroadcast(unbroadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests in `test_multiply_back` passed!\n",
      "All tests in `test_multiply_back_float` passed!\n"
     ]
    }
   ],
   "source": [
    "def multiply_back0(grad_out: Arr, out: Arr, x: Arr, y: Union[Arr, float]) -> Arr:\n",
    "    \"\"\"Backwards function for x * y wrt argument 0 aka x.\"\"\"\n",
    "    if not isinstance(y, Arr):\n",
    "        y = np.array(y)\n",
    "    return unbroadcast(y * grad_out, x)\n",
    "\n",
    "\n",
    "def multiply_back1(grad_out: Arr, out: Arr, x: Union[Arr, float], y: Arr) -> Arr:\n",
    "    \"\"\"Backwards function for x * y wrt argument 1 aka y.\"\"\"\n",
    "    if not isinstance(x, Arr):\n",
    "        x = np.array(x)\n",
    "    return unbroadcast(x * grad_out, y)\n",
    "\n",
    "\n",
    "utils.test_multiply_back(multiply_back0, multiply_back1)\n",
    "utils.test_multiply_back_float(multiply_back0, multiply_back1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests in `test_forward_and_back` passed!\n"
     ]
    }
   ],
   "source": [
    "def forward_and_back(a: Arr, b: Arr, c: Arr) -> Tuple[Arr, Arr, Arr]:\n",
    "    '''\n",
    "    Calculates the output of the computational graph above (g), then backpropogates the gradients and returns dg/da, dg/db, and dg/dc\n",
    "    '''\n",
    "    d = a * b\n",
    "    e = np.log(c)\n",
    "    f = d * e\n",
    "    g = np.log(f)\n",
    "\n",
    "    final_grad_out = np.array([1.0])\n",
    "\n",
    "    dg_df = log_back(grad_out=final_grad_out, out=g, x=f)\n",
    "    dg_dd = multiply_back0(dg_df, f, d, e)\n",
    "    dg_de = multiply_back1(dg_df, f, d, e)\n",
    "\n",
    "    dg_da = multiply_back0(dg_dd, d, a, b)\n",
    "    dg_db = multiply_back1(dg_dd, d, a, b)\n",
    "    dg_dc = log_back(dg_de, e, c)\n",
    "\n",
    "    return dg_da, dg_db, dg_dc\n",
    "\n",
    "\n",
    "utils.test_forward_and_back(forward_and_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84205e65a427e19ff91dd8a92d5a5f2cf0946f21e31957c24c166022f0f50b37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
